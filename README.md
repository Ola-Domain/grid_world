# Deep Q-Learning GridWorld Agent

This project is a visual and interactive implementation of a **Q-Learning agent** solving a 5x5 **GridWorld** environment using **Reinforcement Learning (RL)**. Built with **Python** and **Pygame**, it features custom textures, sound effects, and a responsive stats HUD to monitor the agent's learning process in real time.

---

## ğŸ§  What is Reinforcement Learning?
Reinforcement Learning is a type of Machine Learning where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. In this project:

- The agent learns **which actions lead to better long-term outcomes**.
- A **Q-table** is used to store expected rewards (Q-values) for each state-action pair.
- The agent uses an **epsilon-greedy strategy** to balance **exploration** (trying new actions) and **exploitation** (choosing the best known action).

---

## âœ¨ Features
- âœ… 5x5 bounded GridWorld
- âœ… Special Jump from (2,4) â†’ (4,4) with +5 reward
- âœ… Terminal state at (5,5) with +10 reward
- âœ… Obstacles block movement
- âœ… Q-learning with dynamic epsilon decay
- âœ… Visual grid with sprite-based rendering and digital dashboard
- âœ… Sound effects for terminal and jump events
- âœ… Reward, average reward, epsilon, and time per episode displayed
- âœ… Trail of visited cells drawn during each episode
- âœ… Early stopping if average reward over 30 episodes > 10

---

## ğŸ“ File Structure
```
DeepQ-GridWorld/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ agent.png
â”‚   â”œâ”€â”€ background.png
â”‚   â”œâ”€â”€ goal.png
â”‚   â”œâ”€â”€ jump.png
â”‚   â”œâ”€â”€ obstacle.png
â”‚   â”œâ”€â”€ goal.wav
â”‚   â””â”€â”€ jump.wav
â”œâ”€â”€ config.py              # Environment settings
â”œâ”€â”€ environment.py         # Step function and grid logic
â”œâ”€â”€ q_learning.py          # Q-table learning agent
â”œâ”€â”€ game.py                # Pygame rendering and HUD
â”œâ”€â”€ main.py                # Main training loop
â””â”€â”€ README.md
```

---

## ğŸš€ Installation & Setup
### ğŸ”¹ Step 1: Clone the Repository
```bash
git clone https://github.com/Ola-Domain/QGridWorld.git
cd QGridWorld
```

### ğŸ”¹ Step 2: Install Dependencies
```bash
pip install pygame
```

### ğŸ”¹ Step 3: Run the Simulator
```bash
python main.py
```

You will see a live rendering of the GridWorld, the agent moving step by step, and training statistics at the bottom.

---

## ğŸ¯ Environment Rules
- Grid Size: 5Ã—5
- Start: (2, 1)
- Terminal: (5, 5) â€” reward +10
- Special Jump: (2, 4) â†’ (4, 4) â€” reward +5
- Obstacles: (3,3), (4,3), (3,4), (3,5)
- All other movements: reward -1
- Actions:
  - North = 1
  - South = 2
  - East = 3
  - West = 4

---

## ğŸ¤– Q-Learning Details
- Q(s, a) â† Q(s, a) + Î± [r + Î³ max(Q(s', a')) - Q(s, a)]
- **Learning Rate (Î±)** = how fast we update
- **Discount Factor (Î³)** = how much future rewards matter
- **Epsilon (Îµ)** = exploration rate; decays over episodes
- Q-table is initialized empty and updated through interactions

---

## ğŸ“Š Live Training Stats
- ğŸ” Episode number
- ğŸ“ˆ Total reward in current episode
- ğŸ“‰ Epsilon value (exploration vs exploitation)
- ğŸ“Š Avg reward over last 30 episodes
- â±ï¸ Avg time per episode
- ğŸ’¡ Displayed in a styled digital HUD at the bottom of the screen

---

## ğŸ”§ Customization Tips
- ğŸ¨ Replace textures in `assets/` to change visuals
- ğŸ¼ Add your own `.wav` sound files for jumps or goals
- âš™ï¸ Tune learning rate, gamma, and epsilon decay in `q_learning.py`
- ğŸ§  Modify reward scheme in `environment.py` for experimentation

---

## ğŸ’¡ Future Work
- ğŸ”„ Save and load the Q-table to persist learning progress
- ğŸ§­ Visualize the learned policy with arrows or directional cues
- ğŸ“ˆ Export stats/logs to CSV for offline analysis
- ğŸŒ€ Add stochasticity to rewards or state transitions
- ğŸ§  Implement Deep Q-Network (DQN) with neural network function approximation
- ğŸï¸ Record agent movement into video/GIF for presentations
- ğŸ•¹ï¸ Add keyboard-controlled manual mode for comparison

---

## ğŸ“Œ References
- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction* (2nd ed.). MIT Press.
- Watkins, C. J. C. H., & Dayan, P. (1992). *Q-learning*. Machine Learning, 8(3-4), 279â€“292.
- OpenAI Gym Documentation: https://www.gymlibrary.dev/
- Pygame Docs: https://www.pygame.org/docs/

---

## ğŸ›¡ï¸ License
This project is licensed under the **Ulster University License**.

---

## ğŸ“¬ Contact
- Your Name: [Sulaimon Olasupo](mailto:olasupooladotun6@gmail.com)
- Repository URL: [https://github.com/Ola-Domain/grid_world.git](https://github.com/Ola-Domain/grid_world.git)

---

Happy Training! ğŸ§ ğŸ•¹ï¸ğŸ¯

